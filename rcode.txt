
library(dplyr)
library(ggplot2)
# 
fdata = read.table('fulldata.txt',header = T)





# Algorithm flow 
# initial theta : beta , lambda , pi

# Obtain latentZ (by theta)
# Obtain pi (by latentZ)
# maximize Q (with constraints) and update theta(beta)

# Obtain latentZ (by theta)
# Obtain pi (by latentZ)
# maximize Q (with constraints) and update theta(beta)

# Data preprocessing
N = nrow(fdata)
k=3 # state (k=3)
event_vec = fdata[,2]
time_vec = fdata[,1]

# Denote function 
Qfunc = function(beta_ = 1 , j=1){
  lambda_ = sum(latentZ_mat[,j]*event_vec)/sum(latentZ_mat[,j]*time_vec^beta_)
  sum(latentZ_mat[,j]*event_vec*log(lambda_)+latentZ_mat[,j]*event_vec*log(beta_)+latentZ_mat[,j]*(beta_-1)*event_vec*log(time_vec)-latentZ_mat[,j]*lambda_*time_vec^beta_+latentZ_mat[,j]*log(pi_vec[j]))
}

diffQ = function(beta_ = 1 , j=1){
  sum(latentZ_mat[,j]*event_vec )/beta_+ 
    sum(latentZ_mat[,j]*event_vec *log(time_vec))-
    sum(latentZ_mat[,j]*event_vec )*sum(latentZ_mat[,j]*log(time_vec)*time_vec^beta_ )/sum(latentZ_mat[,j]*time_vec^beta_)
}
twiceDiffQ = function(beta_ = 1 , j=1){
  -sum(latentZ_mat[,j]*event_vec )/beta_^2-
    sum(latentZ_mat[,j]*event_vec )*(sum(latentZ_mat[,j]*log(time_vec)^2*time_vec^beta_)*sum(latentZ_mat[,j]*time_vec^beta_)-sum(latentZ_mat[,j]*log(time_vec)*time_vec^beta_ )^2)/(sum(latentZ_mat[,j]*time_vec^beta_)^2)
}

hazardrate = function(t,beta,lambda){
  beta*lambda *t^(beta-1)
}

weibull_func = function(t,beta,lambda){
  lambda*beta*t^(beta-1)*exp(-lambda*t^beta)
}

# initial theta 
## initial beta , lambda , pi 
initial_beta = c(0.1,1,1.5)
initial_pi = rep(1/k, k)
initial_lambda = c(0.1,0.01,0.01)

beta_vec = initial_beta
pi_vec = initial_pi
lambda_vec = initial_lambda
alphas_vec = 1 / (lambda_vec ^ (1 / beta_vec)) # obtain alpha by lambda 



# Obtain latentZ (by theta)
weibull_pdfs = lapply(1:k, function(i) pi_vec[i]*dweibull(time_vec, scale = alphas_vec[i], shape = beta_vec[i]))
weibull_pdf_sum = Reduce("+", weibull_pdfs)
latentZ_mat = do.call(cbind, lapply(weibull_pdfs, function(pdf) pdf / weibull_pdf_sum))


# maximize Q (with constraints) and update theta(beta)

# Obtain newbeta
update_beta_vec = sapply(1:k, function(i) beta_vec[i]-diffQ(beta_=beta_vec[i],j=i)/twiceDiffQ(beta_=beta_vec[i],j=i))
beta_vec = c(update_beta_vec[1],1,update_beta_vec[3])

# Obtain newlambda 
lambda_vec = sapply(1:k ,  function(i) sum(latentZ_mat[,i]*event_vec)/sum(latentZ_mat[,i]*time_vec^beta_vec[i]))

# Obtain newalpha
alphas_vec = 1 / (lambda_vec ^ (1 / beta_vec)) # obtain alpha by lambda 

# Obtain latentZ (by theta)
# weibull_pdfs = lapply(1:k, function(i) pi_vec[i]*dweibull(time_vec, scale = alphas_vec[i], shape = beta_vec[i]))
weibull_pdfs = lapply(1:k, function(i) pi_vec[i]*weibull_func(time_vec, lambda = lambda_vec[i], beta = beta_vec[i]))
weibull_pdf_sum = Reduce("+", weibull_pdfs)
latentZ_mat = do.call(cbind, lapply(weibull_pdfs, function(pdf) pdf / weibull_pdf_sum))


# Obtain newPi 
pi_vec = colSums(latentZ_mat)/N


latentZ_mat
beta_vec
pi_vec
alphas_vec


hv1 = hazardrate(t=unique(time_vec),beta=beta_vec[1],lambda = lambda_vec[1])
hv2 = hazardrate(t=unique(time_vec),beta=beta_vec[2],lambda = lambda_vec[2])
hv3 = hazardrate(t=unique(time_vec),beta=beta_vec[3],lambda = lambda_vec[3])


ggplot(data=data.frame(time=unique(time_vec),hvalue1=hv1,hvalue2=hv2,hvalue3=hv3))+
  geom_point(aes(time,hvalue1),color='red')+geom_point(aes(time,hvalue2),color='blue')

ggplot(data=data.frame(time=unique(time_vec),hvalue1=hv1,hvalue2=hv2,hvalue3=hv3))+
  geom_point(aes(time,hvalue2),color='blue')+
  geom_point(aes(time,hvalue3),color='black')

ggplot(data=data.frame(time=unique(time_vec),hvalue1=hv1,hvalue2=hv2,hvalue3=hv3))+
  geom_point(aes(time,hvalue1),color='red')+
  geom_point(aes(time,hvalue2),color='blue')+
  geom_point(aes(time,hvalue3),color='black')+
  geom_point(data=hazard_rate_df , aes(time,hazard_rate),color='green')

ggplot(data=data.frame(time=unique(time_vec),hvalue1=hv1,hvalue2=hv2,hvalue3=hv3))+
  geom_point(aes(time,hvalue1),color='red')+
  geom_point(aes(time,hvalue2),color='blue')+
  geom_point(aes(time,hvalue3),color='black')



DecisionBoundary = function(t,j=1){
(pi_vec[j]/pi_vec[2])*(beta_vec[j]/beta_vec[2])*(lambda_vec[j]/lambda_vec[2])*t^(beta_vec[j]-1)*exp(-lambda_vec[j]*t^{beta_vec[j]}+lambda_vec[2]*t)
}

DecisionBoundary = function(t,j=1){
  (pi_vec[j]/pi_vec[2])*(beta_vec[j]/beta_vec[2])*(lambda_vec[j]/lambda_vec[2])*t^(beta_vec[j]-1)*exp(-lambda_vec[j]*t^{beta_vec[j]}+lambda_vec[2]*t)
}

plot(DecisionBoundary(1:300,1))
plot(DecisionBoundary(1:300,3))

# 시간별 위험률 계산 함수
calculate_hazard_rate <- function(data) {
  # 데이터가 시간 순으로 정렬되어 있다고 가정합니다
  time_points <- unique(data$time)
  hazard_rates <- numeric(length(time_points))
  
  for (i in seq_along(time_points)) {
    time <- time_points[i]
    
    # 특정 시간까지 생존한 개체 수
    at_risk <- sum(data$time >= time)
    
    # 해당 시간에 사건이 발생한 개체 수
    events <- sum(data$time == time & data$event == 1)
    
    # 위험률 계산
    hazard_rates[i] <- events / at_risk
  }
  
  return(data.frame(time = time_points, hazard_rate = hazard_rates))
}

# 시간별 위험률 계산
hazard_rate_df <- calculate_hazard_rate(fdata)

# 결과 출력
print(hazard_rate_df)


hazard_rate_df %>% ggplot(aes(time,hazard_rate))+geom_point()












































