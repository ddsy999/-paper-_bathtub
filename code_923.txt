library(reshape2)
library(dplyr)
library(ggplot2)
library(patchwork)


####### Denote function ####

Qfunc = function(beta = 1 ,lambda,latentZ_mat, j=1){
  if(min(event_vec)==1){
    sum(latentZ_mat[,j]*log(lambda))+sum(latentZ_mat[,j]*log(beta))+sum(latentZ_mat[,j]*(beta-1)*log(time_vec))-sum(latentZ_mat[,j]*lambda*time_vec^beta)+sum(latentZ_mat[,j]*log(pi_vec[j]))    
  }else{
  sum(latentZ_mat[,j]*event_vec*log(lambda))+sum(latentZ_mat[,j]*event_vec*log(beta))+sum(latentZ_mat[,j]*(beta-1)*event_vec*log(time_vec))-sum(latentZ_mat[,j]*lambda*time_vec^beta)+sum(latentZ_mat[,j]*log(pi_vec[j]))
  }
}

Qfunc_onlyB = function(beta = 1 ,lambda,latentZ_mat, j=1){
  sum(latentZ_mat[,j]*event_vec)*log(sum(latentZ_mat[,j]*event_vec)/sum(latentZ_mat[,j]*(time_vec^beta)))+sum(latentZ_mat[,j]*event_vec*log(beta))+sum(latentZ_mat[,j]*(beta-1)*event_vec*log(time_vec))-sum(latentZ_mat[,j]*time_vec^beta)*sum(latentZ_mat[,j]*event_vec)/sum(latentZ_mat[,j]*(time_vec^beta))
}

sumQfunc = function(beta_vec,lambda_vec,latentZ_mat ){
  Qfunc(beta=beta_vec[1],lambda_vec[1],latentZ_mat,j=1)+Qfunc(beta=beta_vec[2],lambda_vec[2],latentZ_mat,j=2)+Qfunc(beta=beta_vec[3],lambda_vec[3],latentZ_mat,j=3)
}

hazardrate = function(t,beta,lambda){
  beta*lambda *t^(beta-1)
}

weibull_func = function(t,beta,lambda){
  lambda*beta*t^(beta-1)*exp(-lambda*t^beta)
}

diffB = function(beta,lambda,latentZ_mat,j){
  sum(latentZ_mat[,j]*event_vec/beta + latentZ_mat[,j]*event_vec*log(time_vec)-latentZ_mat[,j]*lambda*time_vec^beta*log(time_vec))
}

diffL = function(beta,lambda,latentZ_mat,j){
  sum(latentZ_mat[,j]*(event_vec/lambda - time_vec^beta))
}

diff_vec = function(beta,lambda,latentZ_mat,j){
  matrix(c(diffB(beta[j],lambda[j],latentZ_mat,j),diffL(beta[j],lambda[j],latentZ_mat,j)),2,1)
}


HessianQB2 = function(beta,lambda,latentZ_mat,j){
  -sum(latentZ_mat[,j]*event_vec )/(beta^2)-sum(latentZ_mat[,j]*time_vec^beta*(log(time_vec))^2)*lambda
}

HessianQL2 = function(beta,lambda,latentZ_mat,j){
  -1/(lambda^2) * sum(latentZ_mat[,j]*event_vec )
}

HessianQBL = function(beta,lambda,latentZ_mat,j){
  - sum(latentZ_mat[,j]* time_vec^beta *log(time_vec) )
}

HessianMat = function(beta,lambda , latentZ_mat,l){
  matrix(c(HessianQB2(beta[l],lambda[l] , latentZ_mat, j=l),
           HessianQBL(beta[l],lambda[l] , latentZ_mat, j=l),
           HessianQBL(beta[l],lambda[l] , latentZ_mat, j=l),
           HessianQL2(beta[l],lambda[l] , latentZ_mat, j=l)
  ),2,2)
}

DecisionBoundary = function(t,beta_vec,lambda_vec,j=1){
  (pi_vec[j]/pi_vec[2])*(beta_vec[j]/beta_vec[2])*(lambda_vec[j]/lambda_vec[2])*t^(beta_vec[j]-1)*exp(-lambda_vec[j]*t^{beta_vec[j]}+lambda_vec[2]*t)
}



# 
Maximize_theta2 = function(beta=1,lambda=1,latentZ,j=2){
  new_lambda = sum(latentZ[,j]*event_vec)/sum(latentZ[,j]*time_vec)
  return(c(beta,new_lambda))
}


Maximize_BarrierMethod_theta1 = function(beta,lambda,latentZ,bp=1,j=1){
  
  # Old
  theta = matrix(c(beta,lambda),2,1)
  Lfuncion_Value = bp*Qfunc(beta,lambda,latentZ,j)-log(beta)-log(1-beta)-log(lambda)
  
  # Diff vec
  temp_diff_vec = c(bp*diffB(beta,lambda,latentZ_mat,j)+(2*beta-1)/(beta*(1-beta)),
                    bp*diffL(beta,lambda,latentZ_mat,j)-1/(lambda))
  # Diff Hessian
  temp_B2 = bp*HessianQB2(beta,lambda,latentZ_mat,j)+1/(beta^2)+1/(1-beta)^2
  temp_L2 = bp*HessianQL2(beta,lambda,latentZ_mat,j)+1/lambda^2
  temp_BL = bp*HessianQBL(beta,lambda,latentZ_mat,j)
  temp_Hessian = c(temp_B2,temp_BL,temp_BL,temp_L2)
  
  diff_vec = matrix(temp_diff_vec,2,1)
  Hessian_mat = matrix(temp_Hessian,2,2)
  
  # Update theta
  newtheta = theta - solve(Hessian_mat)%*%diff_vec
  return(newtheta)
}

Maximize_BarrierMethod_theta3 = function(beta,lambda,latentZ,bp=1,j=3){
  
  # Old
  theta = matrix(c(beta,lambda),2,1)
  Lfuncion_Value = bp*Qfunc(beta,lambda,latentZ,j)-log(beta-1)-log(lambda)
  
  # Diff vec
  temp_diff_vec = c(bp*diffB(beta,lambda,latentZ_mat,j)-1/(beta-1),
                    bp*diffL(beta,lambda,latentZ_mat,j)-1/(lambda))
  # Diff Hessian
  temp_B2 = bp*HessianQB2(beta,lambda,latentZ_mat,j)+1/(beta-1)^2
  temp_L2 = bp*HessianQL2(beta,lambda,latentZ_mat,j)+1/lambda^2
  temp_BL = bp*HessianQBL(beta,lambda,latentZ_mat,j)
  temp_Hessian = c(temp_B2,temp_BL,temp_BL,temp_L2)
  
  diff_vec = matrix(temp_diff_vec,2,1)
  Hessian_mat = matrix(temp_Hessian,2,2)
  
  # Update theta
  newtheta = theta - solve(Hessian_mat)%*%diff_vec
  return(newtheta)
}

scale_to_max <- function(x) {
  return(x / max(x))
}
scale_rows_to_sum1 <- function(mat) {
  return(t(apply(mat, 1, function(x) x / sum(x))))
}


############
# How to Identify a Bathtub Hazard Rate
# 107p

# fdata = read.table('Aarest_data.txt',header = T)
# fdata = read.table('CNC_data.txt',header = T)

fdata = read.table('/Users/choijisoo/Documents/Github/Aarest_data.txt',header = T)
# fdata = read.table('/Users/choijisoo/Documents/Github/Aarest_data_censored_rot1.txt',header = T)
# fdata = read.table('/Users/choijisoo/Documents/Github/Aarest_data_censored_rot2.txt',header = T)
# fdata = read.table('/Users/choijisoo/Documents/Github/FRT_censord.txt',header = T)
# fdata = read.table('/Users/choijisoo/Documents/Github/CNC_data.txt',header = T)
# fdata = read.table('/Users/choijisoo/Documents/Github/CNC_data_censored3.txt',header = T)
# fdata = read.table('/Users/choijisoo/Documents/Github/electronic_device.txt',header = T)
# Haupt E, Schabe H. A new model for a lifetime distribution with bathtub shaped failure rate. Mircoelectronic & Reliability 1992;32: 633±9.



# # r 비율로 event를 0으로 랜덤하게 변경
# r <- 0.2  # 예시 비율
# 
# # 변경할 인덱스 선택
# change_indices <- sample(1:nrow(fdata), size = floor(r * nrow(fdata)))
# 
# # 선택된 인덱스의 event 값을 0으로 변경
# fdata$event[change_indices] <- 0
# write.table(fdata,"Aarest_data_censored4.txt")



# Data preprocessing
N = nrow(fdata)
k=3 
event_vec = fdata[,2] %>% as.numeric()
time_vec = fdata[,1]%>% as.numeric()
time_vec = time_vec/max(time_vec*1.1)
time_vec = time_vec
tot=1e-6

# 7개의 열을 가진 빈 data.frame 생성
theta_df <- data.frame(matrix(ncol = 7, nrow = 0))
column_names <- c("beta1", "lambda1", "beta2", "lambda2", "beta3", "lambda3", "sumQfunc")
colnames(theta_df) <- column_names

## initial beta , lambda , pi 
# initial_beta = c(0.5,1,62)
# initial_lambda = c(1.5,0.00003,3)
# initial_lambda = c(2.7,1.69,1.68)
# initial_pi = c(1,6,1)

initial_beta = c(0.7,1,5)
# initial_lambda = c(1,2,1)
# initial_lambda = c(0.01,2,3)
initial_pi = c(1,4,1)
initial_pi = initial_pi / sum(initial_pi)

## Parameters initialize beta,pi
beta_vec = initial_beta
pi_vec = initial_pi

## Parameter initialize LatantVariable 
latentZ_mat = data.frame(matrix(0,N,k))
phase1_latent = sapply( time_vec, function(i) exp(-i)) %>% scale_to_max
phase2_latent = 1/2
phase3_latent = sapply( time_vec, function(i) exp(i)) %>% scale_to_max
latentZ_mat[,1]=phase1_latent
latentZ_mat[,2]=phase2_latent
latentZ_mat[,3]=phase3_latent
latentZ_mat = scale_rows_to_sum1(latentZ_mat)

## Parameter initialize Lambda 
# lambda_vec = initial_lambda
if(min(event_vec)==1){
  lambda_vec = sapply( 1:k , function(i) sum(latentZ_mat[,i])/sum(latentZ_mat[,i]*(time_vec^beta_vec[i])))
}else{
  lambda_vec = sapply( 1:k , function(i) sum(latentZ_mat[,i]*event_vec)/sum(latentZ_mat[,i]*(time_vec^beta_vec[i])))
}



## Parameter theta
theta_vec = lapply(1:3, function(i) matrix(c(beta_vec[i],lambda_vec[i]),2,1))




for( i in 1:2000){
  print(i)
  
  #### E-step ####
  # Obtain latentZ (by theta)
  print(c(beta_vec,bp) %>% round(4))
  weibull_pdfs = lapply(1:k, function(i) pi_vec[i]*weibull_func(time_vec, lambda = lambda_vec[i], beta = beta_vec[i]))
  weibull_pdf_sum = Reduce("+", weibull_pdfs)
  latentZ_mat = do.call(cbind, lapply(weibull_pdfs, function(pdf) pdf / weibull_pdf_sum)) 
  ################
  
  #### M-step ####
  pi_vec = colSums(latentZ_mat)/N
  
  ################
  
  
  # Update theta
  
  # beta1를 최대화할 함수 정의
  objective_function_1<- function(beta, lambda, latentZ_mat, j=1,bp) {
    Q_value <- Qfunc(beta, lambda, latentZ_mat, j)
    # 음수로 반환하여 최대화를 위해 minimize 방향으로 조정
    return(-(Qfunc(beta,lambda,latentZ_mat,j)+(log(beta)+log(1-beta)+log(lambda))/bp))
    # return(-(Qfunc_onlyB(beta,lambda,latentZ_mat,j)+(log(beta)+log(1-beta)+log(lambda))/bp))
  }
  # beta3를 최대화할 함수 정의
  objective_function_3<- function(beta, lambda, latentZ_mat, j=3,bp) {
    Q_value <- Qfunc(beta, lambda, latentZ_mat, j)
    # 음수로 반환하여 최대화를 위해 minimize 방향으로 조정
    return(-(Qfunc(beta,lambda,latentZ_mat,j)+(log(beta-1)+log(lambda))/bp))
    # return(-(Qfunc_onlyB(beta,lambda,latentZ_mat,j)+(log(beta-1)+log(lambda))/bp))
  }
  
  
  
  lambda_iter1 = lambda_vec[1]
  lambda_iter3 = lambda_vec[3]
  bp=1
  for( m in 1:1000){
    bp=1.01*bp
    new_beta1 = optimize(objective_function_1, interval = c(0.001, 0.99),
                         lambda = lambda_iter1, latentZ_mat = latentZ_mat, j = 1,bp, maximum = F)$minimum
    
    # new_lambda1 = optimize(objective_function_1, interval = c(0.001, 99999),
    #                        beta = new_beta1, latentZ_mat = latentZ_mat, j = 1,bp, maximum = F)$minimum
    
    new_beta3 = optimize(objective_function_3, interval = c(1.001,99999),
                         lambda = lambda_iter3, latentZ_mat = latentZ_mat, j = 3,bp, maximum = F)$minimum
    
    # new_lambda3 = optimize(objective_function_3, interval = c(0.001, 99999),
    #                        beta = new_beta3, latentZ_mat = latentZ_mat, j = 3,bp, maximum = F)$minimum
    
    if(min(event_vec)==1){
      lambda_iter1 = sum(latentZ_mat[,1])/sum(latentZ_mat[,1]*(time_vec^new_beta1))
      lambda_iter3 = sum(latentZ_mat[,3])/sum(latentZ_mat[,3]*(time_vec^new_beta3))
    }else{
      lambda_iter1 = sum(latentZ_mat[,1]*event_vec)/sum(latentZ_mat[,1]*(time_vec^new_beta1))
      lambda_iter3 = sum(latentZ_mat[,3]*event_vec)/sum(latentZ_mat[,3]*(time_vec^new_beta3))  
    }
    
  }
  
  
  # Update Parameter 
  beta_vec[1] = new_beta1
  beta_vec[2] = 1
  beta_vec[3] = new_beta3
  
  if(min(event_vec)==1){
    lambda_vec[1] = sum(latentZ_mat[,1])/sum(latentZ_mat[,1]*(time_vec^beta_vec[1]))
    lambda_vec[2] = sum(latentZ_mat[,2])/sum(latentZ_mat[,2]*(time_vec^beta_vec[2]))
    lambda_vec[3] = sum(latentZ_mat[,3])/sum(latentZ_mat[,3]*(time_vec^beta_vec[3]))
  }else{
    lambda_vec[1] = sum(latentZ_mat[,1]*event_vec)/sum(latentZ_mat[,1]*(time_vec^beta_vec[1]))
    lambda_vec[2] = sum(latentZ_mat[,2]*event_vec)/sum(latentZ_mat[,2]*(time_vec^beta_vec[2]))
    lambda_vec[3] = sum(latentZ_mat[,3]*event_vec)/sum(latentZ_mat[,3]*(time_vec^beta_vec[3]))  
  }
  
  
  
  
  theta_vec = lapply(1:3, function(i) matrix(c(beta_vec[i],lambda_vec[i]),2,1))
  theta_df = rbind(theta_df,c(beta_vec[1],lambda_vec[1],beta_vec[2],lambda_vec[2],beta_vec[3],lambda_vec[3],sumQfunc(beta_vec,lambda_vec,latentZ_mat)))
  colnames(theta_df) <- column_names
  
  # stop rule 
  difference = (theta_vec[[1]][1]-beta_vec[1])^2+(theta_vec[[2]][1]-beta_vec[2])^2+(theta_vec[[3]][1]-beta_vec[3])^2+
    (theta_vec[[1]][2]-lambda_vec[1])^2+(theta_vec[[2]][2]-lambda_vec[2])^2+(theta_vec[[3]][2]-lambda_vec[3])^2
  
}






BBL=seq(0.0001,1,0.0001)
theaa = NULL

for( i in 1:length(BBL)){
  theaa=c(theaa,Qfunc_onlyB(BBL[i],lambda_vec[1],latentZ_mat,j=1) )
}

data.frame(Beta = BBL,Q=theaa) %>% ggplot(aes(x=Beta,y=Q))+geom_point()


# Hazard rate 
hv1 = hazardrate(t=unique(time_vec),beta=beta_vec[1],lambda = lambda_vec[1])
hv2 = hazardrate(t=unique(time_vec),beta=beta_vec[2],lambda = lambda_vec[2])
hv3 = hazardrate(t=unique(time_vec),beta=beta_vec[3],lambda = lambda_vec[3])

# 첫 번째 ggplot
plot1 <- ggplot(data=data.frame(time=unique(time_vec),hvalue1=hv1,hvalue2=hv2,hvalue3=hv3)) +
  geom_point(aes(time, hvalue1), color='red') +
  geom_point(aes(time, hvalue2), color='blue')

# 두 번째 ggplot
plot2 <- ggplot(data=data.frame(time=unique(time_vec),hvalue1=hv1,hvalue2=hv2,hvalue3=hv3)) +
  geom_point(aes(time, hvalue2), color='blue') +
  geom_point(aes(time, hvalue3), color='black')

# 두 개의 그림을 결합하여 하나로 표시
combined_plot <- plot1 + plot2

# 결합된 그림을 출력
print(combined_plot)


plot(theta_df[,'sumQfunc'])
plot(theta_df[50:nrow(theta_df),'beta1'])
plot(theta_df[,'beta2'])
plot(theta_df[,'beta3'])

plot(theta_df[,'lambda1'])
plot(theta_df[,'lambda2'])
plot(theta_df[,'lambda3'])


pi_vec
lambda_vec


diffB(beta_vec[1],lambda_vec[1],latentZ_mat,j=1)
#beta2 는 미분한게 0이다 처음부터 의미가 없음 
diffB(beta_vec[3],lambda_vec[3],latentZ_mat,j=3)

diffL(beta_vec[1],lambda_vec[1],latentZ_mat,j=1)
diffL(beta_vec[2],lambda_vec[2],latentZ_mat,j=2)
diffL(beta_vec[3],lambda_vec[3],latentZ_mat,j=3)



ggplot(data = data.frame(time = unique(time_vec), hvalue1 = hv1, hvalue2 = hv2, hvalue3 = hv3)) +
  geom_point(aes(time, hvalue1), color = 'red') +
  geom_line(aes(time, hvalue1), color = 'red') +   # hvalue1에 대해 선 추가
  geom_point(aes(time, hvalue2), color = 'blue') +
  geom_line(aes(time, hvalue2), color = 'blue') +  # hvalue2에 대해 선 추가
  geom_point(aes(time, hvalue3), color = 'black') +
  geom_line(aes(time, hvalue3), color = 'black')   # hvalue3에 대해 선 추가


plot(DecisionBoundary(seq(0.001,0.999,by=0.01),beta_vec,lambda_vec,j=1))
plot(DecisionBoundary(seq(0.001,0.999,by=0.01),beta_vec,lambda_vec,j=3))

data.frame(time= seq(0.001,2,by=0.01), DB=DecisionBoundary( seq(0.001,2,by=0.01),beta_vec,lambda_vec,j=3)) %>% ggplot(aes(x=time,y=DB))+geom_point()+geom_line()

data.frame(time= seq(0.001,5,by=0.01), DB=DecisionBoundary( seq(0.001,5,by=0.01),beta_vec,lambda_vec,j=1)) %>% ggplot(aes(x=time,y=DB))+geom_point()+geom_line()


DBdata = data.frame(time=seq(0.0001,0.999,by=0.01), DB1 = DecisionBoundary(seq(0.001,0.999,by=0.01),beta_vec,lambda_vec,j=1) , DB3=DecisionBoundary(seq(0.001,0.999,by=0.01),beta_vec,lambda_vec,j=3))
DB1plot = DBdata %>% ggplot(aes(x=time,y=DB1))+geom_point()+geom_line()+geom_hline(yintercept =1,color='red')
DB3plot = DBdata %>% ggplot(aes(x=time,y=DB3))+geom_point()+geom_line()+geom_hline(yintercept =1,color='red')
print(DB1plot+DB3plot)





# Load packages
library(survival)
library(survminer)
# Fit Kaplan-Meier model
km_fit <- survfit(Surv(time_vec, event_vec) ~ 1)
# Approximate hazard function as the negative log of the survival function
hazard_rates <- -diff(log(km_fit$surv))
times <- km_fit$time[-1]  # Adjust time points to match hazard rates length

# Basic plot using base R
plot(times, hazard_rates, type = 's', main = "Approximated Hazard Function from KM Estimator",
     xlab = "Time", ylab = "Hazard Rate", col = "blue")

# Enhanced plot using ggplot2 through survminer
library(ggplot2)
hazard_df <- data.frame(time = times, hazard = hazard_rates)
ggplot(hazard_df, aes(x = time, y = hazard)) +
  geom_step(col = "blue") +
  labs(title = "Approximated Hazard Function from KM Estimator",
       x = "Time", y = "Hazard Rate")


pi_vec[1]*hv1+pi_vec[2]*hv2+pi_vec[3]*hv3



# Load necessary library
library(survival)
# Define Weibull model for survival data
weibull_fit <- survreg(Surv(time_vec, event_vec) ~ 1, dist = "weibull")
# Extract scale and shape parameters
scale <- exp(weibull_fit$scale)  # Scale parameter in R's survreg is given in log scale
shape <- 1 / weibull_fit$scale  # Shape parameter is the reciprocal of scale in R's parameterization
# Calculate hazard rate function
hazard_rate <- function(t) {
  shape / scale * (t / scale)^(shape - 1)
}
# Plotting the hazard rate over time
time_values <- unique(time_vec)
hazard_values <- sapply(time_values, hazard_rate)
# Plot
plot(time_values, hazard_values, type = 'l', col = 'blue', 
     xlab = 'Time', ylab = 'Hazard Rate', main = 'Estimated Hazard Rate using Weibull Model')


# 위볼 모델 적합
weibull_fit <- survreg(Surv(time_vec, event_vec) ~ 1, dist = 'weibull')

# 모델로부터 해저드 레이트 계산
hazard_estimated <- function(t) {
  shape <- 1 / weibull_fit$scale
  scale <- exp(weibull_fit$scale)
  (shape / scale) * (t / scale)^(shape - 1)
}
hazard_estimated(unique(time_vec))

